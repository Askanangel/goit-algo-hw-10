# Домашнє завдання — Порівняння жадібного алгоритму та ДП + Монте-Карло для інтегралів

## Завдання 1: решта монетами

**Набір монет:** {COINS}

### Реалізовані функції
- `find_coins_greedy(amount)` — жадібний підхід: беремо найбільший можливий номінал, доки не наберемо суму.
- `find_min_coins(amount)` — динамічне програмування, що знаходить **мінімальну** кількість монет.

### Коректність та відмінності
- Для канонічних валютних наборів (на кшталт {COINS}) жадібний алгоритм зазвичай дає **оптимальну** кількість монет.  
- `DP` гарантує оптимум **для будь-якого** набору монет, але має вищу обчислювальну складність.

### Складність
- `Greedy`: `O(k)` де `k` — кількість номіналів (після сортування), простір `O(1)`.
- `DP`: `O(amount * k)` за часом і `O(amount)` за пам'яттю, бо будує таблицю від `0` до `amount`.

### Емпіричні результати (ваші значення можуть трохи відрізнятися)
- Середній час на 100 випадкових сум у [1, 10_000]:
  - `Greedy`: ~{g_time:.4f} с
  - `DP`:     ~{dp_time:.4f} с

- Стрес-тест (семпли):
{stress_df.to_markdown(index=False)}

**Висновки:** Для великих сум `Greedy` майже миттєвий і дуже простий у реалізації. `DP` масштабується лінійно від `amount` і споживає суттєво більше пам'яті, тому для великих сум та канонічних наборів монет краще використовувати жадібний алгоритм. Якщо ж набір монет нестандартний або потрібна **гарантія оптимуму** — застосовуйте `DP`.

# Завдання 2 — Обчислення визначеного інтеграла методом Монте‑Карло

**Функція:** `f(x) = x^2`  
**Проміжок інтегрування:** `[a, b] = [0.0, 2.0]`  
**Аналітичне значення:** ∫_{0.0}^{2.0} x² dx = (b³ - a³)/3 = **2.6666666667**

## Алгоритм
Використано стандартний підхід Монте‑Карло:
1. Генеруємо `N` рівномірних точок `x_i ∼ U(a, b)`.
2. Обчислюємо середнє `\overline{f} = (1/N) \sum f(x_i)`.
3. Оцінка інтеграла: `\hat I_N = (b - a) * \overline{f}`.
4. Оцінка стандартної похибки: `(b - a) * s_f / \sqrt{N}`, де `s_f` — вибіркове СКВ `f(x)`.

## Порівняння з точним/базовим результатом
- SciPy quad: 2.6666666667 (оцінка похибки 2.96e-14)

- Аналітика: **2.6666666667**

Див. таблицю *"Monte Carlo vs Analytic — f(x)=x^2 on [0,2]"* у вікні вище з результатами для `N = [100, 1000, 10000, 100000]`: там наведено оцінку Монте‑Карло, оцінену стандартну похибку та абсолютну помилку.

## Висновки
- Похибка Монте‑Карло зменшується приблизно як `O(1/\sqrt{N})`. Це видно з того, що при збільшенні `N` оцінка збігається до аналітичного значення.
- Метод простий у реалізації, стійкий до «важких» функцій і добре масштабується паралельно.
- Мінуси: повільна збіжність порівняно з детерміністичними методами на 1D відрізку (трапеції/Сімпсон), але незамінний у високих розмірностях або коли аналітичний інтеграл складний/недоступний.

## Код
```python
import numpy as np, math

def monte_carlo_integral(f, a, b, samples=100_000, rng=None):
    if rng is None:
        rng = np.random.default_rng()
    x = rng.uniform(a, b, size=samples)
    fx = f(x)
    est = (b - a) * fx.mean()
    se = (b - a) * fx.std(ddof=1) / math.sqrt(samples)
    return est, se
```
